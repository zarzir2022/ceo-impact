import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

pd.set_option('display.max_rows', None)

#Импортируем спаршенные данные
df = pd.read_excel(r"aktsii.xlsx")

df.describe()

#Чтобы проверить зависимость между возрастом, ROA и ROS, построим диаграмму рассеивания. Но прежде, чем сделать это,
#нам необходимо очистить данные от выбросов. Сделаем это с помощью метода квартилей.

#Формируем датафреймы ROA и ROS, которые будем анализировать. Из dfROA исключаем столбец ROS и из dfROS исключаем столбец ROA
dfROA = df.loc[:, ~df.columns.isin(["ROS"])]
dfROS = df.loc[:, ~df.columns.isin(["ROA"])]

#Очищаем датафрейм ROS от выбросов ROA
Q1_ROA = dfROA['ROA'].quantile(0.25)
Q3_ROA = dfROA['ROA'].quantile(0.75)
IQR_ROA = Q3_ROA-Q1_ROA
dfROA = dfROA[~(dfROA['ROA'] < Q1_ROA-1.5*IQR_ROA ) | (dfROA['ROA'] > Q3_ROA+1.5*IQR_ROA)]

#Очищаем датафрейм ROS от выбросов ROS
Q1_ROS = dfROS['ROS'].quantile(0.25)
Q3_ROS = dfROS['ROS'].quantile(0.75)
IQR_ROS = Q3_ROS-Q1_ROS
dfROS = dfROS[~(dfROS['ROS'] < Q1_ROS-1.5*IQR_ROS ) | (dfROS['ROS'] > Q3_ROS+1.5*IQR_ROS)]


#После удаления выбросов мы видим, что ROS имел 7 выбросов, а ROA 8 выбросов (всего в выборке 98 значений)
#Теперь можно перейти непосредственно к анализу влияния переменных на ROS и ROA
[dfROS["TICKER"].count(), dfROA["TICKER"].count()]

#Посмотрим на средние и медианные значения финансовых показателей по рынку. Как видим, средние и медианные значения
# ROS и ROA у мужчин выше, чем у женщин. Однако нельзя сказать, что разница очень значительна.


#Для ROS
df_for_analyze_ROA = dfROA[["CEO's gender", "ROA"]].replace([0,1], ["Female", "Male"])
df_for_analyze_mean_ROA = df_for_analyze_ROA.groupby(["CEO's gender"]).mean()
df_for_analyze_mean_ROA.round(2)
df_for_analyze_mean_ROA["ТИП"] = "Mean"

df_for_analyze_median_ROA = df_for_analyze_ROA.groupby(["CEO's gender"]).median()
df_for_analyze_median_ROA.round(2)
df_for_analyze_median_ROA["ТИП"] = "Median"


#Аналогично для ROS
df_for_analyze_ROS = dfROS[["CEO's gender", "ROS"]].replace([0,1], ["Female", "Male"])
df_for_analyze_mean_ROS = df_for_analyze_ROS.groupby(["CEO's gender"]).mean()
df_for_analyze_mean_ROS.round(2)
df_for_analyze_mean_ROS["ТИП"] = "Mean"

df_for_analyze_median_ROS = df_for_analyze_ROS.groupby(["CEO's gender"]).median()
df_for_analyze_median_ROS.round(2)
df_for_analyze_median_ROS["ТИП"] = "Median"


pd.concat([df_for_analyze_mean_ROA, df_for_analyze_median_ROA, df_for_analyze_mean_ROS, df_for_analyze_median_ROS], axis=1)

#Построим гистограмму распределния ROS и ROA в разрезе пола, чтобы проверить, действительно ли прослеживается связь.
#0 - CEO женщина, 1 - мужчина. Как видим из гистограммы, большинство значений сконцентрировались ближе к середине.
#к области медианных и средних значений за исключением отдельных выбросов. В абсолютном выражении все компании
#сконцентрировались в области от -0.2 до 0.2 для ROA и -0.5 до 0.5 для ROS. Явного полового перекоса в выбросах выше
#выше или ниже средних и медианных значений для общей выборки по рынку не наблюдается.

f, axes = plt.subplots(1, 2, figsize=(15, 5))


sns.histplot(dfROA, x = "ROA", bins=15, hue= """CEO's gender""", ax=axes[0])
sns.histplot(dfROS, x = "ROS", bins=15, hue= """CEO's gender""",  ax=axes[1])

#Проведём последний тест корреляции между половым распределением и ROA/ROS. Как видим, корреляция фактически отсутствует.
#Мы не будем включать переменную пола в итоговое уравнение регрессии.

corrROA = dfROA[["CEO's gender", "ROA"]]
corrROS = dfROS[["ROS"]]
corr = pd.concat([corrROA,corrROS], axis = 1)
sns.heatmap(corr.corr(), annot=True)

#Посмотрим на средние и медианные значения финансовых показателей по рынку. Как видим, средние и медианные значения
# ROS и ROA у генеральных директоров-россиян выше, чем у иностранцев. Причём разница довольно значительна.


#Для ROS
df_for_analyze_ROA = dfROA[["CEO's nationality", "ROA"]].replace([0,1], ["Иностранец", "Русский"])
df_for_analyze_mean_ROA = df_for_analyze_ROA.groupby(["CEO's nationality"]).mean()
df_for_analyze_mean_ROA.round(2)
df_for_analyze_mean_ROA["ТИП"] = "Mean"

df_for_analyze_median_ROA = df_for_analyze_ROA.groupby(["CEO's nationality"]).median()
df_for_analyze_median_ROA.round(2)
df_for_analyze_median_ROA["ТИП"] = "Median"


#Аналогично для ROS
df_for_analyze_ROS = dfROS[["CEO's nationality", "ROS"]].replace([0,1], ["Иностранец", "Русский"])
df_for_analyze_mean_ROS = df_for_analyze_ROS.groupby(["CEO's nationality"]).mean()
df_for_analyze_mean_ROS.round(2)
df_for_analyze_mean_ROS["ТИП"] = "Mean"

df_for_analyze_median_ROS = df_for_analyze_ROS.groupby(["CEO's nationality"]).median()
df_for_analyze_median_ROS.round(2)
df_for_analyze_median_ROS["ТИП"] = "Median"


pd.concat([df_for_analyze_mean_ROA, df_for_analyze_median_ROA, df_for_analyze_mean_ROS, df_for_analyze_median_ROS], axis=1)

#Построим гистограмму распределния ROS и ROA в разрезе национальности, чтобы проверить, действительно ли прослеживается связь.
#0 - CEO россиянин, 1 - иностранец. Как видим из гистограммы, практически во всех группах ROA и ROS больше CEO-россиян.
#Это объясняется довольно просто - как правило генеральные директора в российских компаниях - это россияне, поэтому
#едва ли гистограмма поможет нам в проверке гипотезы о значимости переменной национальности. Тем не менее,
#даже в такой ситуации видно, что те компании, где генеральные директора иностранцы чаще превалируют в группах с ROS и ROA ниже
#среднего по рынку.


f, axes = plt.subplots(1, 2, figsize=(15, 5))


sns.histplot(dfROA, x = "ROA", bins=15, hue= """CEO's nationality""", ax=axes[0])
sns.histplot(dfROS, x = "ROS", bins=15, hue= """CEO's nationality""",  ax=axes[1])

#Проведём последний тест корреляции между национальностью и ROA/ROS. Как видим, корреляция есть, хоть и слабая.
#На контрасте со значениями корреляции по полу эту переменную следует включить в уравнение регрессии и проверить её значимость
#На других тестах уже при работе с самим уравнением в будущем.

corrROA = dfROA[["CEO's nationality", "ROA"]]
corrROS = dfROS[["ROS"]]
corr = pd.concat([corrROA,corrROS], axis = 1)
sns.heatmap(corr.corr(), annot=True)

#Теперь построим диаграммы рассеивания на основе полученных данных. Как видим, наблюдается довольно очевидная прямая зависимость
#Чем выше возраст директора, тем лучшие финансовые показатели у фирмы. Подтвердим нашу гипотезу также корреляционным анализом.
#Что и требовалось ожидать - есть среднеумеренная связь между показателями возраста директора и финансовыми результатами.


f, axes = plt.subplots(2, 2, figsize=(10, 10))

sns.scatterplot(dfROA[["CEO's age", "ROA"]], x = "CEO's age", y = "ROA", ax=axes[0,0])
sns.scatterplot(dfROS[["CEO's age", "ROS"]], x = "CEO's age", y = "ROS",ax=axes[0,1])

sns.heatmap(dfROA[["CEO's age", "ROA"]].corr(), annot=True, ax=axes[1,0])
sns.heatmap(dfROS[["CEO's age", "ROS"]].corr(), annot=True, ax=axes[1,1])

#Построим диаграммы рассеивания и корреляционные матрицы уровня образования. Обе диаграммы показали довольно хаотичную связь:
#нельзя точно увидеть какой-то тренд между уровнем образования и финансовыми показателями. При этом корреляционный анализ
#Тоже дал неоднозначные результаты - между уровнем образования и ROA наблюдается слабая связь со стремлением к средней.
#В то же время между ROS и уровнем образования связь не наблюдается вообще. Возможно, связь между ROA и уровнем образования
#можно объяснить тем, что директоров с несколькими высшими (8 - 10 лет обучения) чаще берут на работу именно крупные компании
#и назначают на высокие должности. Но при этом не факт, что такие директора будут генерировать прибыль, что объясняет
#отсутствие связи между образованием и ROS. Не будем включать эту переменную в уравнение регрессии.

f, axes = plt.subplots(2, 2, figsize=(10, 10))

sns.scatterplot(dfROA[["CEO's education", "ROA"]], x = "CEO's education", y = "ROA", ax=axes[0,0])
sns.scatterplot(dfROS[["CEO's education", "ROS"]], x = "CEO's education", y = "ROS",ax=axes[0,1])

sns.heatmap(dfROA[["CEO's education", "ROA"]].corr(), annot=True, ax=axes[1,0])
sns.heatmap(dfROS[["CEO's education", "ROS"]].corr(), annot=True, ax=axes[1,1])



#Отбираем данные, которые нужно нормализовать и для которых нужно проверить корреляцию с целевыми переменными. 
dfNormROA = dfROA.loc[:, ~dfROA.columns.isin(['TICKER'])]
#Сглаживаем данные с помощью логарифма
dfNormROA = np.cbrt(dfNormROA)

#Отбрасываем лишние для матрицы столбцы
corrROS= dfNormROA.loc[:, ~dfNormROA.columns.isin(["CEO's gender", "CEO's age", "CEO's nationality", "CEO's education"])]
sns.heatmap(corrROS.corr(), annot=True)

#Отбираем данные, которые нужно нормализовать и для которых нужно проверить корреляцию с целевыми переменными. 
dfNormROS = dfROS.loc[:, ~dfROS.columns.isin(['TICKER'])]
#Сглаживаем данные с помощью логарифма
dfNormROS = np.cbrt(dfNormROS)

#Отбрасываем лишние для матрицы столбцы
corrROS= dfNormROS.loc[:, ~dfNormROS.columns.isin(["CEO's gender", "CEO's age", "CEO's nationality", "CEO's education"])]
sns.heatmap(corrROS.corr(), annot=True)

#Перейдём к построению моделей. Для этого импортируем эконометрические библиотеки и подготовим датафрейм на нормализованных данных

import statsmodels.api as sm
import statsmodels.formula.api as smf
import scipy

class olsRegression:

    def __init__(self, y, x):
            self.y = y #целевая переменная
            self.x = x #матрица регрессоров
            #Результаты модели
            self.results = sm.OLS(self.y, self.x).fit()

class errorsTests(olsRegression):

    def importanceTest(self, alfa):
        results = self.results
        importantVars = pd.DataFrame(abs(results.params/results.bse), columns=["t"])
        importantVars["t_crit"] = scipy.stats.t.ppf(1-alfa/2, results.df_resid)
        importantVars["Important?"] = importantVars["t"] > importantVars["t_crit"]
        return importantVars

    def residualsTest(self): #Проверка случайности остатков модели
        results = self.results
        y = self.y
        x = self.x
        #Первым в датафрейм идёт массив значений целевой переменной y. Название столбца y присваивается в переменную main_var
        residuals_test = pd.DataFrame(y)
        main_var = residuals_test.columns[0]

            #Так как мы потенциально не знаем состав столбцов матрицы регрессоров x, мы используем цикл, чтобы мманипулировать ими.
            #Так, в датафрейм мы с помощью цикла загоняем столбец матрицы x и коэффициент этого столбца, а затем это значение отнимаем
            #от целевой переменной до тех пор, пока регрессоры не кончатся. Первоначально столбец residuals будет равен целевой переменной
            #и по мере цикла это значение будет переприсваиваться 
        residuals_test["residuals"] = residuals_test[main_var]

        for col in x.columns:
            residuals_test[col] = x[col]
            residuals_test[f"coef {col}"] = results.params[col]
            residuals_test["residuals"] = residuals_test["residuals"] - residuals_test[col]*residuals_test[f"coef {col}"]

                #Переносим столбец остатков в конец для удобства
        errors = residuals_test["residuals"]
        residuals_test = residuals_test.drop("residuals", axis = 1)
        residuals_test["residuals"] = errors

                #Суммируем регрессоры и сортируем по ним
        residuals_test["Regressors_Modules"] = abs(x.drop(["const"], axis = 1).sum(axis = 1))
        residualsChecking = residuals_test.sort_values(by = "Regressors_Modules")
        return residualsChecking
        
    def halfsTest(self):
        y = self.y
        x = self.x

        y_first_half = y[0 : int(len(y)/2)]
        x_first_half = x[0 : int(len(y)/2)]

        y_second_half = y[int(len(y)/2) : int(len(y))]
        x_second_half = x[int(len(y)/2) : int(len(y))]

        results_first_half = sm.OLS(y_first_half, x_first_half).fit()
        results_second_half = sm.OLS(y_second_half, x_second_half).fit()

        halfsComparison = pd.concat([results_first_half.params, results_second_half.params], axis = 1).rename(columns={0: "1st half", 1: "2nd half"})
        return halfsComparison
        
class HausMarkovCheck(olsRegression):
            
    def olsLearnData(self, controln): #Фунция построения модели

        y_Learn = self.y[controln : ]
        x_Learn = self.x[controln : ]
        results_Learn = sm.OLS(y_Learn, x_Learn).fit()
        return results_Learn.summary()

        #Проведение F-теста
    def Ftest(self, alfa, controln):
        y_Learn = self.y[controln : ]
        x_Learn = self.x[controln : ]
        results = sm.OLS(y_Learn, x_Learn).fit()

        f_crit = scipy.stats.f.ppf(q=1-alfa, dfn=len(results.params), dfd=len(y_Learn) - len(results.params))
        fvalue = results.fvalue
            
        fTest = pd.DataFrame({"F-value": [fvalue], "F-критическое": [f_crit]})
        fTest["Результат"] = fTest["F-value"]>fTest["F-критическое"]
        return fTest
        
    def gqTest(self, controln, dropValue):

        y_Learn = self.y[controln : ]
        x_Learn = self.x[controln : ]

        #Тест Готфрида-Квандта
        gq = sm.stats.diagnostic.het_goldfeldquandt(y_Learn, x_Learn, drop=dropValue)
        gq = "p-value gq равно " + str(gq[1])
        return gq
        
    def dwTest(self, controln):    
        from statsmodels.stats.stattools import durbin_watson
        y_Learn = self.y[controln : ]
        x_Learn = self.x[controln : ]
        results = sm.OLS(y_Learn, x_Learn).fit()
        dw = durbin_watson(results.resid)
        dw = "Статистика DW равна " + str(dw)
        return dw
        
class adequatCheck(olsRegression):

    def adequat_test(self, alfa, controln):
    #q0 = xT*(XT*X)**-1*x
        y_Learn = self.y[controln : ]
        x_Learn = self.x[controln : ]
        results = sm.OLS(y_Learn, x_Learn).fit()
            
        x_controln = self.x[0 : controln]
        y_controln = self.y[0 : controln]

        x = x_controln.transpose()
        XT = x_Learn.transpose()
        X = x_Learn
        xT = x_controln
        q = np.dot(
                np.dot(xT,
                    np.linalg.inv(
                            np.dot(XT,X))), x)[0][0]

        t_crit = scipy.stats.t.ppf(1-alfa/2, results.df_resid)
        S = np.std(results.resid)*(1+q)**0.5

        y_prognoz = results.predict(x_controln)
            

        yPredictions = pd.DataFrame()

        yPredictions["Фактические"] = y_controln
        yPredictions["y min"] = y_prognoz-S*t_crit
        yPredictions["y max"] = y_prognoz+S*t_crit

        return yPredictions

        

#Регрессия с основными переменными (ROA)

y = dfNormROA["ROA"]
x = dfNormROA[["CEO's age", "CEO's nationality"]]
x = sm.add_constant(x)

sm.OLS(y, x).fit().summary()

#Регрессия со вспомогательными переменными

y = dfNormROA["ROA"]
x = dfNormROA[["ЦЕНА", "ПРИБЫЛЬ", "FCF", "CEO's age", "CEO's nationality"]]
x = sm.add_constant(x)

sm.OLS(y, x).fit().summary()

#Важными оказались переменные Прибыль, возраст и национальность. Исключим лишние переменные и повторим тест
errorsTests(y,x).importanceTest(0.05)

y = dfNormROA["ROA"]
x = dfNormROA[["ПРИБЫЛЬ", "CEO's age", "CEO's nationality"]]
x = sm.add_constant(x)


sm.OLS(y, x).fit().summary()

#Теперь все переменные значимы
errorsTests(y,x).importanceTest(0.05)

errorsTests(y,x).halfsTest()

#Остатки случайные, значит все важные переменные были включены.

errorsTests(y,x).residualsTest()



y = dfNormROA["ROA"]
x = dfNormROA[["ПРИБЫЛЬ", "CEO's age", "CEO's nationality"]]
x = sm.add_constant(x)

HausMarkovCheck(y,x).Ftest(alfa = 0.05, controln = 5)


y = dfNormROA["ROA"]
x = dfNormROA[["ПРИБЫЛЬ", "CEO's age", "CEO's nationality"]]
x = sm.add_constant(x)

HausMarkovCheck(y,x).Ftest(alfa = 0.05, controln = 15)

sm.OLS(y[5:], x[5:]).fit().summary()

HausMarkovCheck(y,x).gqTest(controln=5, dropValue = 0.2)

HausMarkovCheck(y,x).dwTest(controln=5)

adequatCheck(y,x).adequat_test(alfa = 0.05, controln=15)

#Регрессия с основными переменными (ROA)

y = dfNormROS["ROS"]
x = dfNormROS[["CEO's age", "CEO's nationality"]]
x = sm.add_constant(x)

sm.OLS(y, x).fit().summary()

y = dfNormROS["ROS"]
x = dfNormROS[["ЦЕНА", "ПРИБЫЛЬ", "FCF", "Собственный капитал (EQUITY)", "CEO's age", "CEO's nationality"]]
x = sm.add_constant(x)

sm.OLS(y, x).fit().summary()

#Важными оказались все переменные кроме цены и FCF. Исключим лишние переменные и повторим тест
errorsTests(y,x).importanceTest(0.05)

y = dfNormROS["ROS"]
x = dfNormROS[["ПРИБЫЛЬ", "Собственный капитал (EQUITY)", "CEO's age", "CEO's nationality"]]
x = sm.add_constant(x)

sm.OLS(y, x).fit().summary()

#Теперь все переменные значимы
errorsTests(y,x).importanceTest(0.05)


errorsTests(y,x).halfsTest()

#Остатки случайные, значит все важные переменные были включены.

errorsTests(y,x).residualsTest()

HausMarkovCheck(y,x).Ftest(alfa = 0.05, controln = 15)

sm.OLS(y[5:], x[5:]).fit().summary()

HausMarkovCheck(y,x).gqTest(controln=15, dropValue = 0.2)

HausMarkovCheck(y,x).dwTest(controln=15)

adequatCheck(y,x).adequat_test(alfa = 0.05, controln=15)





